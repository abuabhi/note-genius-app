
import { useState, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Card, CardContent } from "@/components/ui/card";
import { Loader2, RotateCcw, Wand2 } from "lucide-react";
import { Badge } from "@/components/ui/badge";
import { OCRControls } from "./ocr/OCRControls";
import { ImagePreview } from "./ocr/ImagePreview";
import { TextOutput } from "./ocr/TextOutput";
import { ProcessingIndicator } from "./ocr/ProcessingIndicator";
import { ErrorDisplay } from "./ocr/ErrorDisplay";
import { analyzeContentForTitleAndSubject } from "@/utils/contentAnalysisUtils";
import { supabase } from "@/integrations/supabase/client";
import { enhanceImage } from "@/utils/ocrUtils";
import { useToast } from "@/hooks/use-toast";

interface ImageProcessorProps {
  imageUrl: string;
  onReset: () => void;
  onTextExtracted: (text: string) => void;
  selectedLanguage: string;
  onLanguageChange: (language: string) => void;
  isPremiumUser?: boolean;
  onTitleGenerated?: (title: string) => void;
  onSubjectGenerated?: (subject: string) => void;
}

export const ImageProcessor = ({
  imageUrl,
  onReset,
  onTextExtracted,
  selectedLanguage,
  onLanguageChange,
  isPremiumUser = false,
  onTitleGenerated,
  onSubjectGenerated
}: ImageProcessorProps) => {
  const [useOpenAI, setUseOpenAI] = useState(isPremiumUser);
  const [enhanceImageOption, setEnhanceImageOption] = useState(false);
  const [autoGenerated, setAutoGenerated] = useState(false);
  const [recognizedText, setRecognizedText] = useState("");
  const [isProcessing, setIsProcessing] = useState(false);
  const [processingError, setProcessingError] = useState<string | null>(null);
  const [confidence, setConfidence] = useState<number | null>(null);
  const [processedAt, setProcessedAt] = useState<string | null>(null);
  const { toast } = useToast();

  // Auto-generate title and subject when text is extracted
  useEffect(() => {
    if (recognizedText && !autoGenerated) {
      const analysis = analyzeContentForTitleAndSubject(recognizedText);
      
      if (onTitleGenerated && analysis.suggestedTitle !== "Scanned Note") {
        onTitleGenerated(analysis.suggestedTitle);
      }
      
      if (onSubjectGenerated && analysis.suggestedSubject !== "Uncategorized") {
        onSubjectGenerated(analysis.suggestedSubject);
      }
      
      setAutoGenerated(true);
      console.log('Auto-generated metadata:', analysis);
    }
  }, [recognizedText, autoGenerated, onTitleGenerated, onSubjectGenerated]);

  // Forward text changes to parent
  useEffect(() => {
    onTextExtracted(recognizedText);
  }, [recognizedText, onTextExtracted]);

  const processImage = async () => {
    if (!imageUrl) return;
    
    setIsProcessing(true);
    setProcessingError(null);
    
    try {
      console.log("Starting OCR processing...");
      
      // Get current user session
      const { data: { session } } = await supabase.auth.getSession();
      const userId = session?.user?.id;

      // Apply enhancement if requested
      let processedUrl = imageUrl;
      if (enhanceImageOption) {
        try {
          console.log("Enhancing image before OCR processing");
          processedUrl = await enhanceImage(imageUrl);
        } catch (enhanceError) {
          console.error('Image enhancement error:', enhanceError);
          toast({
            title: "Enhancement Warning",
            description: "Image enhancement failed, processing original image.",
            variant: "destructive",
          });
        }
      }

      console.log("Calling process-image edge function");
      
      // Call our Supabase edge function for OCR processing
      const { data, error } = await supabase.functions.invoke('process-image', {
        body: { 
          imageUrl: processedUrl,
          language: selectedLanguage,
          userId: userId,
          useOpenAI: useOpenAI && isPremiumUser,
          enhanceImage: enhanceImageOption
        }
      });
      
      if (error) {
        console.error("Edge function error:", error);
        throw new Error(error.message || "Failed to process image");
      }
      
      if (!data || !data.success) {
        console.error("OCR processing failed:", data);
        throw new Error(data?.error || "OCR service returned an error");
      }
      
      if (!data.text) {
        console.error("No text returned from OCR service:", data);
        throw new Error("No text was extracted from the image");
      }
      
      console.log("OCR processing completed successfully:", data);
      
      // Process response data
      const resultText = data.text;
      setRecognizedText(resultText);
      setConfidence(data.confidence);
      setProcessedAt(data.processedAt);
      setAutoGenerated(false); // Reset auto-generation flag
      
      const providerName = data.provider === 'openai' ? 'OpenAI' : 
                           data.provider === 'google-vision' ? 'Google Vision' : 
                           data.provider === 'mock' ? 'Demo Mode' :
                           'OCR Engine';
      
      toast({
        title: "Text Extracted",
        description: `OCR processing complete with ${Math.round((data.confidence || 0) * 100)}% confidence using ${providerName}.`,
      });
      
    } catch (error) {
      console.error("OCR processing error:", error);
      const errorMsg = (error as Error).message || "Failed to process image";
      setProcessingError(errorMsg);
      toast({
        title: "Processing Failed",
        description: "Could not extract text from the image. Please try again or check if the image is clear and readable.",
        variant: "destructive",
      });
    } finally {
      setIsProcessing(false);
    }
  };

  const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setRecognizedText(e.target.value);
  };

  const handleReset = () => {
    setRecognizedText("");
    setProcessingError(null);
    setConfidence(null);
    setProcessedAt(null);
    setAutoGenerated(false);
    onReset();
  };

  const handleRetryOCR = async () => {
    await processImage();
  };

  const getLanguageName = (code: string): string => {
    const languages = {
      eng: "English",
      fra: "French", 
      spa: "Spanish",
      deu: "German",
      chi_sim: "Chinese",
      jpn: "Japanese"
    };
    
    return languages[code as keyof typeof languages] || code;
  };

  return (
    <Card className="w-full">
      <CardContent className="p-4 space-y-4">
        {/* Image Preview */}
        <ImagePreview 
          imageUrl={imageUrl} 
          onReset={handleReset}
          onRetryOCR={handleRetryOCR}
          isProcessing={isProcessing}
        />

        {/* OCR Controls */}
        <OCRControls
          isEnhanced={enhanceImageOption}
          onEnhancementChange={() => setEnhanceImageOption(!enhanceImageOption)}
          useOpenAI={useOpenAI}
          onOpenAIChange={() => setUseOpenAI(!useOpenAI)}
          isProcessing={isProcessing}
          isPremiumUser={isPremiumUser}
        />

        {/* Process Button */}
        {!recognizedText && !isProcessing && (
          <Button
            onClick={processImage}
            disabled={isProcessing}
            className="w-full bg-mint-500 hover:bg-mint-600 text-white"
          >
            Extract Text
          </Button>
        )}

        {/* Processing Indicator */}
        {isProcessing && (
          <ProcessingIndicator
            useOpenAI={useOpenAI}
            isPremiumUser={isPremiumUser}
            isEnhanced={enhanceImageOption}
            language={selectedLanguage}
            getLanguageNameByCode={getLanguageName}
          />
        )}

        {/* Error Display */}
        {processingError && <ErrorDisplay error={processingError} />}

        {/* Text Output */}
        {recognizedText && (
          <div className="space-y-2">
            {autoGenerated && (
              <div className="flex items-center gap-2">
                <Badge variant="secondary" className="text-xs">
                  <Wand2 className="h-3 w-3 mr-1" />
                  Auto-generated title & subject
                </Badge>
              </div>
            )}
            <TextOutput
              recognizedText={recognizedText}
              handleTextChange={handleTextChange}
              confidence={confidence}
              processedAt={processedAt}
              useOpenAI={useOpenAI}
              isPremiumUser={isPremiumUser}
            />
          </div>
        )}

        {/* Reset Button */}
        <div className="flex justify-between items-center pt-2">
          <Button
            variant="outline"
            size="sm"
            onClick={handleReset}
            className="flex items-center gap-2"
          >
            <RotateCcw className="h-4 w-4" />
            Reset
          </Button>
          
          {recognizedText && (
            <p className="text-xs text-muted-foreground">
              {recognizedText.length} characters extracted
            </p>
          )}
        </div>
      </CardContent>
    </Card>
  );
};
